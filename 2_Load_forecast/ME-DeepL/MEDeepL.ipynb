{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MEDeepL.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPah6TAlvS/VkC/v6GtgfQR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfHi1YDSiAoB","executionInfo":{"status":"ok","timestamp":1651038485724,"user_tz":-540,"elapsed":2668,"user":{"displayName":"‍허성구[학생](공과대학 환경학및환경공학과)","userId":"12827334309014994112"}},"outputId":"9f49bdf4-b4db-4874-b20d-e96b9407962d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/hanhwa_AA/Hanhwa_AA/2_Load_forecast/ME-DeepL\n"]}],"source":["# Google drive로 Mount\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# 폴더 이동\n","%cd '/content/drive/My Drive/hanhwa_AA/Hanhwa_AA/2_Load_forecast/ME-DeepL/'\n"," #수정 필요"]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"Proposed_hybrid multimodal_model_COD.ipynb\n","Automatically generated by Colaboratory.\n","Original file is located at\n","    https://colab.research.google.com/drive/1cRewIg4RXvfeY1nRS34W0pj73MnTtXLG\n","\"\"\"\n","\n","# Commented out IPython magic to ensure Python compatibility.\n","import os\n","\n","#s.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # ,1,2,3,4,5'\n","\n","# call libraries\n","import tensorflow as tf\n","import numpy as np\n","from keras.models import Sequential\n","from tensorflow.keras import callbacks\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.layers import Input, TimeDistributed\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import GRU, ReLU, LeakyReLU, ELU\n","from keras.layers import Dropout\n","from tensorflow.keras.layers import Conv1D, Conv2D, ConvLSTM2D, MaxPool1D\n","from tensorflow.keras.layers import BatchNormalization\n","import matplotlib.pyplot as plt\n","import math\n","import pandas as pd\n","import scipy.io as sio\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","import time\n","\n","\n","def mean_absolute_percentage_error(y_true, y_pred):\n","    ## Note: does not handle mix 1d representation\n","    # if _is_1d(y_true):\n","    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n","\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","\n","from keras.layers import CuDNNGRU, CuDNNLSTM, Activation\n","\n","# from tensorflow.keras.utils import multi_gpu_model\n","\n","\n","print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n","\n","\n","# tf.compat.v1.disable_eager_execution()\n","\n","# Convert an array of values into a dataset matrix → Sliding Window\n","\n","\n","def create_dataset(data, look_back=1):\n","    dataX, dataY = [], []\n","    for i in range(len(data) - look_back):\n","        a = data[i:(i + look_back+1)]\n","        dataX.append(a)\n","        dataY.append(data[i + look_back])\n","    return np.array(dataX), np.array(dataY)\n","\n","\n","# Load data\n","# The each influent data was decomposed into sub-layers, by HHT-EMD\n","\n","df = pd.read_csv('IMF.csv', delimiter=',')\n","dataset = df.values\n","dataset = dataset.T\n","\n","L, len_IMF =dataset.shape\n","for iz in range(len_IMF-1):\n","    IMF=dataset[:,iz]\n","\n","\n","    # Determine length of train set and test set\n","    trainL = math.ceil(L * 4 / 5)\n","    testL = L - trainL\n","\n","    col = len_IMF - 1\n","\n","    # Data preparation according to determined length\n","    look_back = 24  # Window length\n","    step = +1  # Prediction step (Maximum step must be equal to mxstep)\n","\n","\n","    # Data Propagation: single IMF !!!\n","\n","    data = IMF\n","    trainX = data[:trainL - step, ]\n","    y_train = data[look_back +step :trainL, ]\n","    x_train, YY = create_dataset(trainX, look_back)\n","\n","\n","    testX = data[trainL:L - step]\n","    y_test = data[look_back + trainL + step:L]\n","    x_test, YY = create_dataset(testX, look_back)\n","    # x_test is converted to 3-dimension data by using moving window\n","\n","    predictX = dataset[L - step - look_back:L]\n","    x_predict, YY = create_dataset(predictX, look_back)\n","\n","    print(x_train.shape)\n","    print(y_train.shape)\n","    print(x_test.shape)\n","    print(y_test.shape)\n","\n","    # From the sliding window analysis, we divide the Sliding window data into the Sliding window sub-layers\n","    # Data structure: (Batch size, time step (window size), Sub-layers(HHT-based EMD))\n","\n","    # Model structure:\n","    # Input data 1(EMD) ->\n","    # Encoder: 1D CNN -> RNN(LSTM or GRU) -> Dense\n","    # Decoder: -> Ensamble -> Forecasting\n","\n","    x_train= x_train.reshape(1103,25,1)\n","    x_test = x_test.reshape(256,25,1)\n","\n","    size_TimeStep, size_Window, size_EMD = x_train.shape\n","\n","    Input_data = [x_train[:, :, ii].reshape(size_TimeStep, size_Window, 1) for ii in range(size_EMD)]\n","\n","    model = tf.keras.Sequential()\n","    model.add(Conv1D(filters=20, kernel_size=7, strides=1, kernel_initializer='random_uniform', padding='same'))\n","    model.add(MaxPool1D(pool_size=2, strides=1, padding='same'))\n","    model.add(Conv1D(filters=20, kernel_size=7, strides=1, kernel_initializer='random_uniform', padding='same'))\n","    model.add(MaxPool1D(pool_size=2, strides=1, padding='same'))\n","    model.add(Conv1D(filters=20, kernel_size=7, strides=1, kernel_initializer='random_uniform', padding='same'))\n","    model.add(MaxPool1D(pool_size=2, strides=1, padding='same'))\n","    model.add(Conv1D(filters=20, kernel_size=7, strides=1, kernel_initializer='random_uniform', padding='same'))\n","    model.add(MaxPool1D(pool_size=2, strides=1, padding='same'))\n","    model.add(Conv1D(filters=20, kernel_size=7, strides=1, kernel_initializer='random_uniform', padding='same'))\n","    model.add(MaxPool1D(pool_size=2, strides=1, padding='same'))\n","    model.add(GRU(32, ))  ## return_sequences=True,))\n","    # model.add(GRU(16))\n","\n","    model.add(Dense(16))\n","    model.add(Dense(4))\n","    model.add(Dense(1))\n","    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy', 'mse', 'mae', 'mape'])\n","\n","    if iz == len_IMF - 1:\n","        model = tf.keras.Sequential()\n","\n","        #model.add(Conv1D(filters=20, kernel_size=7, strides=1, kernel_initializer='random_uniform', padding='same'))\n","        #model.add(MaxPool1D(pool_size=2, strides=1, padding='same'))\n","        model.add(GRU(32, ))  ## return_sequences=True,))\n","        # model.add(GRU(16))\n","\n","        # model.add(Dense(4))\n","        model.add(Dense(4))\n","        model.add(Dense(1))\n","        model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy', 'mse', 'mae', 'mape'])\n","\n","    history = model.fit(x_train, y_train, epochs=200, batch_size=128, verbose=0, validation_split=0.1)\n","\n","    # Generates output predictions for the input samples.\n","    trainPredict = model.predict(x_train)\n","\n","    size_TimeStep, size_Window, size_EMD = x_test.shape\n","\n","    Input_Testdata = [x_test[:, :, ii].reshape(size_TimeStep, size_Window, 1) for ii in range(size_EMD)]\n","\n","    testPredict = model.predict(x_test)\n","\n","    # Predict = model.predict(x_predict)\n","\n","    trainPredictPlot = np.empty_like(data)\n","    trainPredictPlot[:,] = np.nan\n","    trainPredictPlot[look_back + step:trainL,] = trainPredict.reshape(len(trainPredict))\n","\n","    testPredictPlot = np.empty_like(data)\n","    testPredictPlot[:,] = np.nan\n","    testPredictPlot[look_back + trainL + step:L,] = testPredict.reshape(len(testPredict))\n","\n","    # PredictPlot = np.empty([dataset.shape[0]+step,dataset.shape[1]])\n","    # PredictPlot[:, :] = np.nan\n","    # PredictPlot[L:L+step, :] = Predict\n","\n","\n","    # Calculate the forecasting performance\n","    trainScore = model.evaluate(x_train, y_train, verbose=0)\n","    testScore = model.evaluate(x_test, y_test, verbose=0)\n","\n","    test_r2 = r2_score(y_test, testPredict)\n","\n","    test_mape = mean_absolute_percentage_error(y_test ,testPredict )\n","    test_mae = mean_absolute_error(y_test, testPredict )\n","    test_mse = mean_squared_error(y_test , testPredict )\n","\n","    # Plots the predicted results of the train set and test set\n","\n","\n","    print('IMF: %.4f |, Test Score | R2: %.4f,  MSE: %.4f, MAE: %.4f,MAPE: %.4f' % (\n","        iz+1, test_r2,  test_mse, test_mae, test_mape))\n","\n","\n","    sio.savemat(\"MEDeepL_result\"+str(iz+1)+\".mat\", {\"testPredictPlot\": testPredictPlot})\n","\n","\n","\"\"\"\n","plt.figure()\n","plt.plot(data[:],'k')\n","plt.plot(trainPredictPlot,'b')\n","plt.plot(testPredictPlot,'r')\n","plt.xlabel('Time')\n","plt.ylabel('IMF')\n","plt.show()\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":859},"id":"aKfVnmoaiH6b","executionInfo":{"status":"error","timestamp":1651039317113,"user_tz":-540,"elapsed":276283,"user":{"displayName":"‍허성구[학생](공과대학 환경학및환경공학과)","userId":"12827334309014994112"}},"outputId":"8e672b2e-898b-4a34-ab0b-b7d217a9dddd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is NOT AVAILABLE\n","(1103, 25)\n","(1103,)\n","(256, 25)\n","(256,)\n","IMF: 1.0000 |, Test Score | R2: 0.3357,  MSE: 0.0041, MAE: 0.0460,MAPE: 435.7546\n","(1103, 25)\n","(1103,)\n","(256, 25)\n","(256,)\n","IMF: 2.0000 |, Test Score | R2: 0.9617,  MSE: 0.0005, MAE: 0.0156,MAPE: 853.0646\n","(1103, 25)\n","(1103,)\n","(256, 25)\n","(256,)\n","IMF: 3.0000 |, Test Score | R2: 0.9959,  MSE: 0.0001, MAE: 0.0088,MAPE: 401.1104\n","(1103, 25)\n","(1103,)\n","(256, 25)\n","(256,)\n","IMF: 4.0000 |, Test Score | R2: 0.9995,  MSE: 0.0000, MAE: 0.0011,MAPE: 552.9562\n","(1103, 25)\n","(1103,)\n","(256, 25)\n","(256,)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f6e2b1a8dc88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Generates output predictions for the input samples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}